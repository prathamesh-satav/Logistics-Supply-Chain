{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Logistics Data Cleaning Pipeline - Google Colab\n",
        "\n",
        "## **Step 1: Setup, Load & Map Data**\n",
        "**Description:**\n",
        "We load the dataset and perform a critical \"Column Mapping\" step.\n",
        "* **Fix 1:** We strip whitespace from raw column names to prevent `KeyError`.\n",
        "* **Fix 2:** We rename the columns from your specific file (e.g., `shipping_mode`) to the standard names required for our analysis (e.g., `Shipment Mode`).\n",
        "* **Fix 3:** We create placeholder columns for data that might be missing in the raw file (like `Season`) so the pipeline doesn't break."
      ],
      "metadata": {
        "id": "RZeE35C2FTbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(\"--- STEP 1: Loading & Mapping Real Data ---\")\n",
        "\n",
        "# 1. Load the file\n",
        "filename = 'incom2024_delay_example_dataset.csv'\n",
        "df = pd.read_csv(filename)\n",
        "\n",
        "# 2. Clean Raw Headers (CRITICAL FIX)\n",
        "# Removes hidden spaces like \" shipping_mode \" -> \"shipping_mode\"\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# 3. Map your file's columns to the pipeline names\n",
        "# This tells the code: \"Use 'order_id' when I ask for 'Order ID'\"\n",
        "column_mapping = {\n",
        "    'order_id': 'Order ID',\n",
        "    'shipping_mode': 'Shipment Mode',\n",
        "    'order_date': 'Scheduled Dispatch Date',   # Proxy: Order Date = Scheduled\n",
        "    'shipping_date': 'Actual Dispatch Date',\n",
        "    'order_city': 'Origin',\n",
        "    'customer_city': 'Destination',\n",
        "    'order_item_quantity': 'Package Weight',   # Proxy: Quantity = Weight\n",
        "    'order_item_total_amount': 'Transport Cost', # Proxy: Amount = Cost\n",
        "    'order_status': 'Delivery Priority'\n",
        "}\n",
        "\n",
        "# 4. Apply Renaming\n",
        "df = df.rename(columns=column_mapping)\n",
        "\n",
        "# 5. Handle \"Transporter\" column\n",
        "# Your file doesn't have a 'Carrier' column, so we use Shipment Mode as a proxy\n",
        "# or create a placeholder if you prefer.\n",
        "if 'Transporter' not in df.columns:\n",
        "    df['Transporter'] = df['Shipment Mode']\n",
        "\n",
        "# 6. Create missing columns required for the pipeline\n",
        "required_placeholders = ['Dispatch Delay (Days)', 'Delivery Time (Days)',\n",
        "                         'Season', 'Holiday / Non-Holiday']\n",
        "\n",
        "for col in required_placeholders:\n",
        "    if col not in df.columns:\n",
        "        df[col] = np.nan  # Initialize as empty, we will calculate/fill later\n",
        "\n",
        "# 7. Verification\n",
        "print(f\"Dataset Loaded Successfully.\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(\"Columns available:\", df.columns.tolist())\n",
        "\n",
        "# Check for the column that caused the error previously\n",
        "if 'Shipment Mode' in df.columns:\n",
        "    print(\"\\n✅ SUCCESS: 'Shipment Mode' is ready.\")\n",
        "else:\n",
        "    print(\"\\n❌ ERROR: 'Shipment Mode' is missing.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQUfmdO9Fbst",
        "outputId": "1861116e-5df3-48c5-d5c5-591bbfa9a805"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STEP 1: Loading & Mapping Real Data ---\n",
            "Dataset Loaded Successfully.\n",
            "Shape: (15549, 46)\n",
            "Columns available: ['payment_type', 'profit_per_order', 'sales_per_customer', 'category_id', 'category_name', 'Destination', 'customer_country', 'customer_id', 'customer_segment', 'customer_state', 'customer_zipcode', 'department_id', 'department_name', 'latitude', 'longitude', 'market', 'Origin', 'order_country', 'order_customer_id', 'Scheduled Dispatch Date', 'Order ID', 'order_item_cardprod_id', 'order_item_discount', 'order_item_discount_rate', 'order_item_id', 'order_item_product_price', 'order_item_profit_ratio', 'Package Weight', 'sales', 'Transport Cost', 'order_profit_per_order', 'order_region', 'order_state', 'Delivery Priority', 'product_card_id', 'product_category_id', 'product_name', 'product_price', 'Actual Dispatch Date', 'Shipment Mode', 'label', 'Transporter', 'Dispatch Delay (Days)', 'Delivery Time (Days)', 'Season', 'Holiday / Non-Holiday']\n",
            "\n",
            "✅ SUCCESS: 'Shipment Mode' is ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 2: Detecting Data Issues**\n",
        "**Description:**\n",
        "We scan the now-standardized dataset for dirty data.\n",
        "1.  **Missing Values:** Identifying where data is empty.\n",
        "2.  **Duplicates:** Counting identical rows.\n",
        "3.  **Logic Errors:** Checking for impossible negatives."
      ],
      "metadata": {
        "id": "frKT9L3DFgDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- STEP 2: Detecting Data Issues ---\")\n",
        "\n",
        "# 1. Missing Values (Only showing columns that have nulls)\n",
        "print(\"Missing Values Summary:\")\n",
        "missing = df.isnull().sum()\n",
        "print(missing[missing > 0])\n",
        "\n",
        "# 2. Duplicates\n",
        "duplicates = df.duplicated().sum()\n",
        "print(f\"\\nDuplicated Rows Detected: {duplicates}\")\n",
        "\n",
        "# 3. Logic Checks (Negative Values)\n",
        "check_cols = ['Package Weight', 'Transport Cost', 'Delivery Time (Days)']\n",
        "for col in check_cols:\n",
        "    # Ensure column exists before checking\n",
        "    if col in df.columns:\n",
        "        # Count negatives\n",
        "        neg_count = df[df[col] < 0].shape[0]\n",
        "        if neg_count > 0:\n",
        "            print(f\"Warning: Found {neg_count} negative values in {col}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDRODbWgFkJu",
        "outputId": "b1113804-0539-4e05-87fe-90d22bc62547"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STEP 2: Detecting Data Issues ---\n",
            "Missing Values Summary:\n",
            "Dispatch Delay (Days)    15549\n",
            "Delivery Time (Days)     15549\n",
            "Season                   15549\n",
            "Holiday / Non-Holiday    15549\n",
            "dtype: int64\n",
            "\n",
            "Duplicated Rows Detected: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 3: Clean Dates & Validate Delays**\n",
        "**Description:**\n",
        "This step fixes the timeline data.\n",
        "1.  Convert dates to standard format (`datetime`).\n",
        "2.  **Calculate the Real Delay:** We subtract `Scheduled` from `Actual`.\n",
        "3.  **Overwrite:** We replace the often inaccurate `Dispatch Delay` column with our calculated truth."
      ],
      "metadata": {
        "id": "Nr-47x-MFoAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- STEP 3: Cleaning Dates & Validating Logic (Fixed) ---\")\n",
        "\n",
        "# 1. Convert to datetime with utc=True to handle mixed timezones\n",
        "# This fixes the \"AttributeError\" by ensuring we get a proper datetime64 dtype\n",
        "df['Scheduled Dispatch Date'] = pd.to_datetime(df['Scheduled Dispatch Date'], errors='coerce', utc=True)\n",
        "df['Actual Dispatch Date'] = pd.to_datetime(df['Actual Dispatch Date'], errors='coerce', utc=True)\n",
        "\n",
        "# 2. Drop rows where we have no schedule (cannot measure delay without it)\n",
        "df = df.dropna(subset=['Scheduled Dispatch Date'])\n",
        "\n",
        "# 3. Calculate Delay (Actual - Scheduled)\n",
        "# Now that both are proper datetimes, subtraction creates a Timedelta series\n",
        "df['Delay_Calc'] = (df['Actual Dispatch Date'] - df['Scheduled Dispatch Date']).dt.days\n",
        "\n",
        "# 4. Validation & Overwrite\n",
        "# We trust our calculation over the raw data column\n",
        "df['Dispatch Delay (Days)'] = df['Delay_Calc']\n",
        "\n",
        "print(\"Dates converted (UTC) and delays validated/overwritten.\")\n",
        "# Check the types to confirm fix\n",
        "print(df[['Scheduled Dispatch Date', 'Actual Dispatch Date']].dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8Jr_dc9FpPu",
        "outputId": "fad11eea-19af-4baa-c86b-9315a7e3b478"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STEP 3: Cleaning Dates & Validating Logic (Fixed) ---\n",
            "Dates converted (UTC) and delays validated/overwritten.\n",
            "Scheduled Dispatch Date    datetime64[ns, UTC]\n",
            "Actual Dispatch Date       datetime64[ns, UTC]\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Cleaning Categorical Variables\n",
        "We standardize text columns to ensure reliable grouping and filtering.\n",
        "1.  **Strip:** Remove leading/trailing spaces (e.g., \" Air \" → \"Air\").\n",
        "2.  **Title Case:** Standardize capitalization (e.g., \"AIR\" → \"Air\").\n",
        "3.  **Category Type:** Convert to pandas `category` dtype to save memory and speed up processing."
      ],
      "metadata": {
        "id": "llZ2jtM5FxK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- STEP 4: Cleaning Categorical Variables ---\")\n",
        "\n",
        "# List of categorical columns to clean\n",
        "cat_cols = ['Shipment Mode', 'Transporter', 'Origin', 'Destination',\n",
        "            'Season', 'Delivery Priority', 'Holiday / Non-Holiday']\n",
        "\n",
        "for col in cat_cols:\n",
        "    # Only process columns that actually exist in the dataframe\n",
        "    if col in df.columns:\n",
        "        # 1. Convert to string to handle any mixed types\n",
        "        # 2. Strip whitespace\n",
        "        # 3. Title case for consistency\n",
        "        # 4. Convert to category\n",
        "        df[col] = df[col].astype(str).str.strip().str.title().astype('category')\n",
        "\n",
        "print(\"Categorical variables cleaned and standardized.\")\n",
        "# Verify one column to see the result\n",
        "if 'Shipment Mode' in df.columns:\n",
        "    print(f\"Unique Shipment Modes: {df['Shipment Mode'].unique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juHb88sWFySG",
        "outputId": "4ca5ae48-5102-476c-d839-67a4b246c508"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STEP 4: Cleaning Categorical Variables ---\n",
            "Categorical variables cleaned and standardized.\n",
            "Unique Shipment Modes: ['Standard Class', 'Second Class', 'First Class', 'Same Day']\n",
            "Categories (4, object): ['First Class', 'Same Day', 'Second Class', 'Standard Class']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Cleaning Numeric Columns\n",
        "We clean numerical data to handle errors and outliers:\n",
        "1.  **Force Numeric:** Convert columns to numbers, turning errors (like \"Five\") into `NaN`.\n",
        "2.  **Fix Negatives:** Convert negative weights or costs to positive using `abs()`.\n",
        "3.  **Outlier Capping:** We cap values at the **1st and 99th percentiles**. This removes extreme data entry errors (e.g., a 5000kg package) without deleting rows, preserving the rest of the valid data."
      ],
      "metadata": {
        "id": "WAhIDVuAF1yu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- STEP 5: Cleaning Numeric Columns ---\")\n",
        "\n",
        "num_cols = ['Package Weight', 'Dispatch Delay (Days)', 'Transport Cost', 'Delivery Time (Days)']\n",
        "\n",
        "# 1. Force Numeric Types\n",
        "for col in num_cols:\n",
        "    if col in df.columns:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# 2. Fix Negatives (Impossible values)\n",
        "if 'Package Weight' in df.columns:\n",
        "    df['Package Weight'] = df['Package Weight'].abs()\n",
        "if 'Transport Cost' in df.columns:\n",
        "    df['Transport Cost'] = df['Transport Cost'].abs()\n",
        "\n",
        "# 3. Outlier Capping Function\n",
        "def cap_outliers(series):\n",
        "    # Only cap if there is enough data\n",
        "    if series.count() > 10:\n",
        "        lower = series.quantile(0.01)\n",
        "        upper = series.quantile(0.99)\n",
        "        return series.clip(lower=lower, upper=upper)\n",
        "    return series\n",
        "\n",
        "# 4. Apply Capping\n",
        "print(\"Capping outliers at 1st and 99th percentiles...\")\n",
        "cols_to_cap = ['Package Weight', 'Transport Cost', 'Delivery Time (Days)']\n",
        "\n",
        "for col in cols_to_cap:\n",
        "    if col in df.columns:\n",
        "        original_max = df[col].max()\n",
        "        df[col] = cap_outliers(df[col])\n",
        "        new_max = df[col].max()\n",
        "        if original_max != new_max:\n",
        "             print(f\" -> Capped {col}: Max dropped from {original_max:.2f} to {new_max:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psEwBFN9F2sd",
        "outputId": "d564d432-3690-4a5b-b403-9a5cd7c2b93d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STEP 5: Cleaning Numeric Columns ---\n",
            "Capping outliers at 1st and 99th percentiles...\n",
            " -> Capped Transport Cost: Max dropped from 1939.99 to 453.36\n",
            " -> Capped Delivery Time (Days): Max dropped from nan to nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Missing Value Treatment\n",
        "We fill in missing data (`NaN`) using logic appropriate for each data type:\n",
        "1.  **Numeric:** Impute with the **Median**. (Averages are unsafe in logistics due to skewed data).\n",
        "2.  **Dates:** If `Actual Dispatch Date` is missing, we estimate it as: `Scheduled Date + Median Delay`.\n",
        "3.  **Categorical:** Fill with \"Unknown\"."
      ],
      "metadata": {
        "id": "j5voW9CNF7pN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Numeric Imputation (Median)\n",
        "for col in num_cols:\n",
        "    if df[col].isnull().sum() > 0:\n",
        "        median_val = df[col].median()\n",
        "        df[col] = df[col].fillna(median_val)\n",
        "\n",
        "# 2. Date Imputation\n",
        "# If Actual Date is missing, estimate it using Scheduled + Median Delay\n",
        "median_delay = df['Dispatch Delay (Days)'].median()\n",
        "# Ensure median_delay is not NaN; if it is, default to 0 for timedelta\n",
        "if pd.isna(median_delay):\n",
        "    median_delay = 0\n",
        "df['Actual Dispatch Date'] = df['Actual Dispatch Date'].fillna(\n",
        "    df['Scheduled Dispatch Date'] + pd.to_timedelta(median_delay, unit='D')\n",
        ")\n",
        "\n",
        "# 3. Categorical Imputation\n",
        "for col in cat_cols:\n",
        "    if df[col].isnull().sum() > 0:\n",
        "        df[col] = df[col].cat.add_categories(['Unknown']).fillna('Unknown')\n",
        "\n",
        "# Drop exact duplicates finally\n",
        "df = df.drop_duplicates()\n",
        "print(\"Missing values handled.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4oC9Uz8F8gf",
        "outputId": "8609a054-7690-43da-f05d-28343a0bf41b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values handled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: Feature Engineering\n",
        "We create new columns to support deeper business analysis:\n",
        "1.  **Is_Delayed:** Binary flag (1 = Late, 0 = On Time/Early).\n",
        "2.  **Delay_Category:** buckets delays into \"Early\", \"On Time\", \"Slight\", and \"Serious\".\n",
        "3.  **Route:** Combines Origin and Destination.\n",
        "4.  **Cost_per_kg:** Calculates cost efficiency.\n",
        "5.  **Delivery_Efficiency:** Measures the gap between total time and delay."
      ],
      "metadata": {
        "id": "qKGw2oUtGB-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- STEP 7: Feature Engineering ---\")\n",
        "\n",
        "# 1. Binary Delay\n",
        "if 'Dispatch Delay (Days)' in df.columns:\n",
        "    df['Is_Delayed'] = np.where(df['Dispatch Delay (Days)'] > 0, 1, 0)\n",
        "\n",
        "    # 2. Delay Categories\n",
        "    # Bins: Anything < -0.01 is Early, -0.01 to 0 is On Time, etc.\n",
        "    bins = [-float('inf'), -0.01, 0, 3, float('inf')]\n",
        "    labels = ['Early', 'On Time', 'Slight Delay', 'Serious Delay']\n",
        "    df['Delay_Category'] = pd.cut(df['Dispatch Delay (Days)'], bins=bins, labels=labels)\n",
        "\n",
        "# 3. Route\n",
        "if 'Origin' in df.columns and 'Destination' in df.columns:\n",
        "    df['Route'] = df['Origin'].astype(str) + \" -> \" + df['Destination'].astype(str)\n",
        "\n",
        "# 4. Cost Efficiency\n",
        "if 'Transport Cost' in df.columns and 'Package Weight' in df.columns:\n",
        "    # Avoid division by zero\n",
        "    df['Cost_per_kg'] = df['Transport Cost'] / df['Package Weight'].replace(0, np.nan)\n",
        "\n",
        "# 5. Delivery Efficiency\n",
        "if 'Delivery Time (Days)' in df.columns and 'Dispatch Delay (Days)' in df.columns:\n",
        "    df['Delivery_Efficiency'] = df['Delivery Time (Days)'] - df['Dispatch Delay (Days)']\n",
        "\n",
        "print(\"New Features created successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CxHI_k7GDGN",
        "outputId": "c8e2bb5d-c0b1-4006-a646-f563dd768f22"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STEP 7: Feature Engineering ---\n",
            "New Features created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 8: Final Health Check & Export\n",
        "Finally, we verify the dataset is clean (no nulls, correct types) and export it to a CSV file for reporting or visualization."
      ],
      "metadata": {
        "id": "-kOFrRtpGHJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- STEP 8: Final Health Check & Export ---\")\n",
        "\n",
        "# Final check\n",
        "print(\"\\nFinal Null Counts:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "print(\"\\nFinal Data Types:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "# Export\n",
        "output_filename = \"clean_incom2024_delay_dataset.csv\"\n",
        "df.to_csv(output_filename, index=False)\n",
        "print(f\"\\nSuccessfully saved clean dataset to {output_filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pS5hP8UGJFF",
        "outputId": "75681a7a-b685-4964-8a7b-258ad439f391"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STEP 8: Final Health Check & Export ---\n",
            "\n",
            "Final Null Counts:\n",
            "payment_type                    0\n",
            "profit_per_order                0\n",
            "sales_per_customer              0\n",
            "category_id                     0\n",
            "category_name                   0\n",
            "Destination                     0\n",
            "customer_country                0\n",
            "customer_id                     0\n",
            "customer_segment                0\n",
            "customer_state                  0\n",
            "customer_zipcode                0\n",
            "department_id                   0\n",
            "department_name                 0\n",
            "latitude                        0\n",
            "longitude                       0\n",
            "market                          0\n",
            "Origin                          0\n",
            "order_country                   0\n",
            "order_customer_id               0\n",
            "Scheduled Dispatch Date         0\n",
            "Order ID                        0\n",
            "order_item_cardprod_id          0\n",
            "order_item_discount             0\n",
            "order_item_discount_rate        0\n",
            "order_item_id                   0\n",
            "order_item_product_price        0\n",
            "order_item_profit_ratio         0\n",
            "Package Weight                  0\n",
            "sales                           0\n",
            "Transport Cost                  0\n",
            "order_profit_per_order          0\n",
            "order_region                    0\n",
            "order_state                     0\n",
            "Delivery Priority               0\n",
            "product_card_id                 0\n",
            "product_category_id             0\n",
            "product_name                    0\n",
            "product_price                   0\n",
            "Actual Dispatch Date            0\n",
            "Shipment Mode                   0\n",
            "label                           0\n",
            "Transporter                     0\n",
            "Dispatch Delay (Days)           0\n",
            "Delivery Time (Days)        15549\n",
            "Season                          0\n",
            "Holiday / Non-Holiday           0\n",
            "Delay_Calc                      0\n",
            "Is_Delayed                      0\n",
            "Delay_Category                  0\n",
            "Route                           0\n",
            "Cost_per_kg                     0\n",
            "Delivery_Efficiency         15549\n",
            "dtype: int64\n",
            "\n",
            "Final Data Types:\n",
            "payment_type                             object\n",
            "profit_per_order                        float64\n",
            "sales_per_customer                      float64\n",
            "category_id                             float64\n",
            "category_name                            object\n",
            "Destination                            category\n",
            "customer_country                         object\n",
            "customer_id                             float64\n",
            "customer_segment                         object\n",
            "customer_state                           object\n",
            "customer_zipcode                        float64\n",
            "department_id                           float64\n",
            "department_name                          object\n",
            "latitude                                float64\n",
            "longitude                               float64\n",
            "market                                   object\n",
            "Origin                                 category\n",
            "order_country                            object\n",
            "order_customer_id                       float64\n",
            "Scheduled Dispatch Date     datetime64[ns, UTC]\n",
            "Order ID                                float64\n",
            "order_item_cardprod_id                  float64\n",
            "order_item_discount                     float64\n",
            "order_item_discount_rate                float64\n",
            "order_item_id                           float64\n",
            "order_item_product_price                float64\n",
            "order_item_profit_ratio                 float64\n",
            "Package Weight                          float64\n",
            "sales                                   float64\n",
            "Transport Cost                          float64\n",
            "order_profit_per_order                  float64\n",
            "order_region                             object\n",
            "order_state                              object\n",
            "Delivery Priority                      category\n",
            "product_card_id                         float64\n",
            "product_category_id                     float64\n",
            "product_name                             object\n",
            "product_price                           float64\n",
            "Actual Dispatch Date        datetime64[ns, UTC]\n",
            "Shipment Mode                          category\n",
            "label                                     int64\n",
            "Transporter                            category\n",
            "Dispatch Delay (Days)                     int64\n",
            "Delivery Time (Days)                    float64\n",
            "Season                                 category\n",
            "Holiday / Non-Holiday                  category\n",
            "Delay_Calc                                int64\n",
            "Is_Delayed                                int64\n",
            "Delay_Category                         category\n",
            "Route                                    object\n",
            "Cost_per_kg                             float64\n",
            "Delivery_Efficiency                     float64\n",
            "dtype: object\n",
            "\n",
            "Successfully saved clean dataset to clean_incom2024_delay_dataset.csv\n"
          ]
        }
      ]
    }
  ]
}